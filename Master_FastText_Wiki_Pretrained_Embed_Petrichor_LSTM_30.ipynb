{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master_FastText_Wiki_Pretrained_Embed_Petrichor_LSTM_30",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtindru/petrichor/blob/master/Master_FastText_Wiki_Pretrained_Embed_Petrichor_LSTM_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l0x-pKE_0ue",
        "outputId": "0e581787-0779-4f76-de05-56568b8b26f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nPnI2DA_ptR"
      },
      "source": [
        "# This is location of the data\n",
        "data_url = '/content/gdrive/My Drive/petrichor_new/master_dataset.csv'\n",
        "vector_path = '/content/gdrive/My Drive/petrichor_new/wiki-news-300d-1M.vec'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6_wws-D4oBU"
      },
      "source": [
        "# Top Level Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSCS0M44pnd"
      },
      "source": [
        "# Import the data\n",
        "\n",
        "# We have two different dictonaries, let's just merge them together\n",
        "df_one = pd.read_csv(data_url, sep=',', error_bad_lines=False, encoding='latin1', header=None, names=['word', 'pos', 'meaning'])\n",
        "df_two = pd.read_csv('https://raw.githubusercontent.com/rtindru/petrichor/master/dataset.csv')\n",
        "df = pd.concat([df_one, df_two]).drop('idx', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Di17g0w4vAu"
      },
      "source": [
        "print(df.info())\n",
        "print('---')\n",
        "print(df.word.value_counts()[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-TcF3wr62Zk",
        "outputId": "ab6cbd2a-6a0d-4dfb-cd56-1cc29f4c50bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['label'] = df.word.str.lower()\n",
        "print(len(df.label.unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "262201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kdQYf1723nX",
        "outputId": "cd89cda6-917b-4e71-90bf-f88b53b2591b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df['count'] = df[['label', 'meaning']].groupby(['label']).transform('count')\n",
        "downsized_df = df[(df['count'] > 30)]\n",
        "print('Predicting on {} samples of data'.format(downsized_df.shape))\n",
        "print('Num of unique classes: {}'.format(len(downsized_df.label.unique())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting on (226070, 5) samples of data\n",
            "Num of unique classes: 4233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ8KI4uxqPfY",
        "outputId": "8b048455-68e4-465c-a569-706151afc422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_NB_WORDS = 50000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=-1)\n",
        "tokenizer.fit_on_texts(downsized_df.meaning)\n",
        "sequences = tokenizer.texts_to_sequences(downsized_df.meaning)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "\n",
        "# Assigned maxlen based on the third quartile of frequency distribution of the meaning lengths\n",
        "downsized_df['wordlen'] = downsized_df.meaning.apply(len)\n",
        "print(downsized_df.wordlen.describe())\n",
        "MAX_SEQUENCE_LENGTH = 80\n",
        "\n",
        "X = pd.DataFrame(pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 35195 unique tokens.\n",
            "count    226070.000000\n",
            "mean         63.732052\n",
            "std          49.893732\n",
            "min           3.000000\n",
            "25%          31.000000\n",
            "50%          50.000000\n",
            "75%          82.000000\n",
            "max         942.000000\n",
            "Name: wordlen, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIS4_0nEddd",
        "outputId": "89e9ca65-ad50-4881-bf82-e444234d48f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# import keras.backend as K\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = pd.DataFrame(le.fit_transform(downsized_df.label))\n",
        "number_of_classes = len(le.classes_)\n",
        "\n",
        "\"\"\"\n",
        "# Use train_test_split from scikit\n",
        "# Checkout stratified sampling & splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\n",
        "\n",
        "labels = K.one_hot(K.cast(y,'uint8'), number_of_classes)\n",
        "y_train = K.one_hot(K.cast(y_train,'uint8'), number_of_classes)\n",
        "y_test = K.one_hot(K.cast(y_test,'uint8'), number_of_classes)\n",
        "\n",
        "print('Shape of data tensor:', X.shape)\n",
        "print('Shape of label tensor:', y.shape)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Use train_test_split from scikit\\n# Checkout stratified sampling & splitting\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\\n\\nlabels = K.one_hot(K.cast(y,'uint8'), number_of_classes)\\ny_train = K.one_hot(K.cast(y_train,'uint8'), number_of_classes)\\ny_test = K.one_hot(K.cast(y_test,'uint8'), number_of_classes)\\n\\nprint('Shape of data tensor:', X.shape)\\nprint('Shape of label tensor:', y.shape)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMpHIf1PFCXv",
        "outputId": "24612b25-ec95-44de-86bc-73175a050fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "_X_train, X_test, _y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(_X_train, _y_train, test_size=0.25, random_state = 42)\n",
        "\n",
        "\n",
        "print('Shape of data tensor:', X.shape)\n",
        "print('Shape of label tensor:', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (226070, 80)\n",
            "Shape of label tensor: (226070, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiOCTEJqftL"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, X, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.X = X\n",
        "        self.list_IDs = X.index.values\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = self.X.loc[ID]\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels.loc[ID]\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMzzRMh39_-5"
      },
      "source": [
        "params = {'dim': (80,),\n",
        "          'batch_size': 32,\n",
        "          'n_classes': number_of_classes,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n",
        "\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(X_train, y_train, **params)\n",
        "validation_generator = DataGenerator(X_valid, y_valid, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSOtJQjZn00U",
        "outputId": "2a4c674c-f006-43b6-fb6b-bb141b0a165f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import gensim\n",
        "gn_model = gensim.models.KeyedVectors.load_word2vec_format(vector_path)\n",
        "# gn_model = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/petrichor_new/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwrRPZ-YvZdp"
      },
      "source": [
        "def get_coefficients(word, model):\n",
        "  \"\"\"\n",
        "  Helper method to return coeffs for a model; or zeros!\n",
        "  \"\"\"\n",
        "  try:\n",
        "    return model.get_vector(word)\n",
        "  except KeyError:\n",
        "    return np.zeros(model.wv.vector_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YWiiDcY1wk4",
        "outputId": "e5b8e979-3432-4f9c-a67b-2a55910a006a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Preload the embedding matrix\n",
        "EMBEDDING_DIM = 300  # same as the lenght of the keyed vector\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_matrix[i] = get_coefficients(word, gn_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuPKCImM3wv5",
        "outputId": "1a5e7d44-a50c-4aa0-d811-800a21fd4344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense, Embedding, Dropout, SpatialDropout1D, Bidirectional, LSTM\n",
        "from tensorflow.python.keras import Sequential\n",
        "\n",
        "TRAIN_SAMPLES = len(X_train)\n",
        "LSTM_DIM = 128 \n",
        "NUM_CLASSES = number_of_classes\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index)+1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(LSTM(LSTM_DIM))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 80, 300)           10558800  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4233)              546057    \n",
            "=================================================================\n",
            "Total params: 11,324,505\n",
            "Trainable params: 11,324,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDB7irZ_PjQ6",
        "outputId": "d05c9384-9d76-4f8a-956f-cea098c8c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=training_generator, validation_data=validation_generator, batch_size=64, verbose=True, epochs=100, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2844 - accuracy: 0.0014 - top_k_categorical_accuracy: 0.0069WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2844 - accuracy: 0.0014 - top_k_categorical_accuracy: 0.0069WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1139s 321ms/step - loss: 8.2844 - accuracy: 0.0014 - top_k_categorical_accuracy: 0.0069 - val_loss: 8.2603 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0076\n",
            "Epoch 2/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2401 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2402 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1100s 310ms/step - loss: 8.2402 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2592 - val_accuracy: 0.0017 - val_top_k_categorical_accuracy: 0.0075\n",
            "Epoch 3/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2364 - accuracy: 0.0016 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2364 - accuracy: 0.0016 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1099s 310ms/step - loss: 8.2364 - accuracy: 0.0016 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2582 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 4/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2342 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2342 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1097s 309ms/step - loss: 8.2342 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076 - val_loss: 8.2583 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0075\n",
            "Epoch 5/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2328 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2328 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1088s 306ms/step - loss: 8.2328 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2587 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2315 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2316 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1110s 313ms/step - loss: 8.2316 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077 - val_loss: 8.2589 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 7/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2305 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2305 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1127s 318ms/step - loss: 8.2305 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076 - val_loss: 8.2590 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 8/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2298 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2298 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1142s 322ms/step - loss: 8.2298 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2586 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 9/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2291 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2291 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1086s 306ms/step - loss: 8.2291 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2590 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0075\n",
            "Epoch 10/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2285 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2285 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1080s 304ms/step - loss: 8.2285 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077 - val_loss: 8.2593 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 11/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2282 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2282 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1089s 307ms/step - loss: 8.2282 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0075 - val_loss: 8.2576 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0079\n",
            "Epoch 12/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2278 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2278 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1085s 306ms/step - loss: 8.2278 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0076 - val_loss: 8.2590 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0075\n",
            "Epoch 13/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3548/3549 [============================>.] - ETA: 0s - loss: 8.2273 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - ETA: 0s - loss: 8.2273 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "3549/3549 [==============================] - 1098s 309ms/step - loss: 8.2273 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0077 - val_loss: 8.2582 - val_accuracy: 0.0018 - val_top_k_categorical_accuracy: 0.0075\n",
            "Epoch 14/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1642/3549 [============>.................] - ETA: 9:49 - loss: 8.2225 - accuracy: 0.0018 - top_k_categorical_accuracy: 0.0074"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZETOytyBAcn"
      },
      "source": [
        "# from IPython.display import SVG\n",
        "# from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "# SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
        "#                  rankdir='LR').create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igz4RN_RfbmN"
      },
      "source": [
        "# \"\"\"\n",
        "# steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
        "# validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
        "# \"\"\"\n",
        "# EPOCHS = 5\n",
        "# BATCH_SIZE = 64\n",
        "# STEPS_PER_EPOCH = TRAIN_SAMPLES // BATCH_SIZE\n",
        "# VAL_SPLIT = 0.2 \n",
        "# VALIDATION_STEPS = VAL_SPLIT * TRAIN_SAMPLES // BATCH_SIZE\n",
        "\n",
        "# # https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "\n",
        "# model.fit(X_train, y_train, epochs=EPOCHS,\n",
        "#           shuffle=True, verbose=True)\n",
        "\n",
        "# print(model.metrics_names)\n",
        "# print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FQHBzhHiJ3Q"
      },
      "source": [
        "model.evaluate(X_test, keras.utils.to_categorical(y_test, num_classes=number_of_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q9MkctP5mWs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}